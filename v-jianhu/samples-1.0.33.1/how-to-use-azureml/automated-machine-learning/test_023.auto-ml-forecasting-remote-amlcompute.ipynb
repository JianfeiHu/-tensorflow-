{
    "cells":  [
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "Copyright (c) Microsoft Corporation. All rights reserved.\n",
                                     "\n",
                                     "Licensed under the MIT License."
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "# AutoML 023: Forecasting with Remote Execution using BatchAI (Ubuntu)\n",
                                     "\n",
                                     "In this example, we show how AutoML can be used for energy demand forecasting on BathcAI.\n",
                                     "\n",
                                     "\n",
                                     "Make sure you have executed the [00.configuration](00.configuration.ipynb) before running this notebook.\n",
                                     "\n",
                                     "In this notebook you wiil learn how to:\n",
                                     "1. Create an `Experiment` in an existing `Workspace`.\n",
                                     "2. Attach an BatchAI cluster\n",
                                     "3. Configure AutoML using `AutoMLConfig`.\n",
                                     "4. Train the model using BatchAI cluster.\n",
                                     "5. Get the best fitted model\n",
                                     "5. Testing the fitted model"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Create an Experiment\n",
                                     "\n",
                                     "As part of the setup you have already created an Azure ML `Workspace` object. For AutoML you will need to create an `Experiment` object, which is a named object in a `Workspace` used to run experiments."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "import azureml.core\n",
                                     "import pandas as pd\n",
                                     "import numpy as np\n",
                                     "import os\n",
                                     "import logging\n",
                                     "\n",
                                     "from azureml.core.workspace import Workspace\n",
                                     "from azureml.core.experiment import Experiment\n",
                                     "from azureml.train.automl import AutoMLConfig\n",
                                     "from azureml.train.automl.run import AutoMLRun\n",
                                     "from matplotlib import pyplot as plt\n",
                                     "from matplotlib.pyplot import imshow\n",
                                     "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "ws = Workspace.from_config()\n",
                                     "\n",
                                     "# Choose a name for the run history container in the workspace.\n",
                                     "experiment_name = \u0027timeseries-batchai\u0027\n",
                                     "project_folder = \u0027./sample_projects/timeseries-batchai\u0027\n",
                                     "\n",
                                     "experiment = Experiment(ws, experiment_name)\n",
                                     "\n",
                                     "output = {}\n",
                                     "output[\u0027SDK version\u0027] = azureml.core.VERSION\n",
                                     "output[\u0027Subscription ID\u0027] = ws.subscription_id\n",
                                     "output[\u0027Workspace Name\u0027] = ws.name\n",
                                     "output[\u0027Resource Group\u0027] = ws.resource_group\n",
                                     "output[\u0027Location\u0027] = ws.location\n",
                                     "output[\u0027Project Directory\u0027] = project_folder\n",
                                     "output[\u0027Experiment Name\u0027] = experiment.name\n",
                                     "pd.set_option(\u0027display.max_colwidth\u0027, -1)\n",
                                     "pd.DataFrame(data = output, index = [\u0027\u0027]).T"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Diagnostics\n",
                                     "\n",
                                     "Opt-in diagnostics for better experience, quality, and security of future releases."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "from azureml.telemetry import set_diagnostics_collection\n",
                                     "set_diagnostics_collection(send_diagnostics = True)"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Create Batch AI Cluster\n",
                                     "The cluster is created as Machine Learning Compute and will appear under your workspace.\n",
                                     "\n",
                                     "**Note:** The creation of the Batch AI cluster can take over 10 minutes, please be patient.\n",
                                     "\n",
                                     "As with other Azure services, there are limits on certain resources (e.g. Batch AI cluster size) associated with the Azure Machine Learning service. Please read [this article](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-manage-quotas) on the default limits and how to request more quota."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "from azureml.core.compute import AmlCompute\n",
                                     "from azureml.core.compute import ComputeTarget\n",
                                     "\n",
                                     "# Choose a name for your cluster.\n",
                                     "batchai_cluster_name = \"automlcl-ts\"\n",
                                     "\n",
                                     "found = False\n",
                                     "# Check if this compute target already exists in the workspace.\n",
                                     "cts = ws.compute_targets\n",
                                     "if batchai_cluster_name in cts and cts[batchai_cluster_name].type == \u0027BatchAI\u0027:\n",
                                     "    found = True\n",
                                     "    print(\u0027Found existing compute target.\u0027)\n",
                                     "    compute_target = cts[batchai_cluster_name]\n",
                                     "    \n",
                                     "if not found:\n",
                                     "    print(\u0027Creating a new compute target...\u0027)\n",
                                     "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_D2_V2\", # for GPU, use \"STANDARD_NC6\"\n",
                                     "                                                                #vm_priority = \u0027lowpriority\u0027, # optional\n",
                                     "                                                                max_nodes = 6)\n",
                                     "\n",
                                     "    # Create the cluster.\n",
                                     "    compute_target = ComputeTarget.create(ws, batchai_cluster_name, provisioning_config)\n",
                                     "    \n",
                                     "    # Can poll for a minimum number of nodes and for a specific timeout.\n",
                                     "    # If no min_node_count is provided, it will use the scale settings for the cluster.\n",
                                     "    compute_target.wait_for_completion(show_output = True, min_node_count = None, timeout_in_minutes = 20)\n",
                                     "    \n",
                                     "     # For a more detailed view of current AmlCompute cluster status, use get_status()."
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Add dependencies to the run config\n",
                                     "Timeseries package has some dependency from Pypi, we need to add these to the run config."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "from azureml.core.runconfig import RunConfiguration\n",
                                     "from azureml.core.conda_dependencies import CondaDependencies\n",
                                     "\n",
                                     "# create a new RunConfig object\n",
                                     "conda_run_config = RunConfiguration(framework=\"python\")\n",
                                     "\n",
                                     "# Set compute target to the Linux DSVM\n",
                                     "conda_run_config.target = compute_target\n",
                                     "\n",
                                     "cd = CondaDependencies.create(pip_packages=[\u0027azureml-sdk[automl]\u0027, \u0027dill\u0027, \u0027h5py\u0027, \u0027keras\u0027, \u0027numexpr\u0027, \u0027statsmodels\u0027, \u0027distributed==1.23.1\u0027], conda_packages=[\u0027numpy\u0027])\n",
                                     "conda_run_config.environment.python.conda_dependencies = cd"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Create Get Data File\n",
                                     "For remote executions you should author a `get_data.py` file containing a `get_data()` function. This file should be in the root directory of the project. You can encapsulate code to read data either from a blob storage or local disk in this file.\n",
                                     "In this example, the `get_data()` function returns data using scikit-learn\u0027s [load_digits](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html) method."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "if not os.path.exists(project_folder):\n",
                                     "    os.makedirs(project_folder)"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "%%writefile $project_folder/get_data.py\n",
                                     "\n",
                                     "from sklearn import datasets\n",
                                     "from sklearn.model_selection import train_test_split\n",
                                     "from scipy import sparse\n",
                                     "import numpy as np\n",
                                     "import pandas as pd\n",
                                     "\n",
                                     "def get_data():\n",
                                     "    df = pd.read_csv(\"https://automldata.blob.core.windows.net/datasets/nyc_energy.csv\", parse_dates=[\u0027timeStamp\u0027])\n",
                                     "    train = df[df[\u0027timeStamp\u0027] \u003c \u00272017-02-01\u0027]\n",
                                     "\n",
                                     "    X_train = train[train[\u0027timeStamp\u0027] \u003c \u00272017-01-01\u0027]\n",
                                     "    X_valid = train[train[\u0027timeStamp\u0027] \u003e= \u00272017-01-01\u0027]\n",
                                     "\n",
                                     "    y_train = X_train.pop(\u0027demand\u0027).values\n",
                                     "    y_valid = X_valid.pop(\u0027demand\u0027).values\n",
                                     "\n",
                                     "    return { \"X\" : X_train, \"y\" : y_train, \"X_valid\" : X_valid, \"y_valid\" : y_valid, \"x_raw_column_names\" : train.columns }"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Instantiate AutoML \u003ca class=\"anchor\" id=\"Instatiate-AutoML-Remote-DSVM\"\u003e\u003c/a\u003e\n",
                                     "\n",
                                     "You can specify `automl_settings` as `**kwargs` as well. Also note that you can use a `get_data()` function for local excutions too.\n",
                                     "\n",
                                     "**Note:** When using Batch AI, you can\u0027t pass Numpy arrays directly to the fit method.\n",
                                     "\n",
                                     "|Property|Description|\n",
                                     "|-|-|\n",
                                     "|**task**|forecasting|\n",
                                     "|**primary_metric**|This is the metric that you want to optimize. Classification supports the following primary metrics: \u003cbr\u003e\u003ci\u003eaccuracy\u003c/i\u003e\u003cbr\u003e\u003ci\u003eAUC_weighted\u003c/i\u003e\u003cbr\u003e\u003ci\u003ebalanced_accuracy\u003c/i\u003e\u003cbr\u003e\u003ci\u003eaverage_precision_score_weighted\u003c/i\u003e\u003cbr\u003e\u003ci\u003eprecision_score_weighted\u003c/i\u003e|\n",
                                     "|**iteration_timeout_minutes**|Time limit in minutes for each iteration.|\n",
                                     "|**iterations**|Number of iterations. In each iteration AutoML trains a specific pipeline with the data.|\n",
                                     "|**max_concurrent_iterations**|Maximum number of iterations that would be executed in parallel. This should be less than the number of cores on the DSVM.|"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "time_column_name = \u0027timeStamp\u0027\n",
                                     "automl_settings = {\n",
                                     "    \"iteration_timeout_minutes\": 5,\n",
                                     "    \"iterations\": 10,\n",
                                     "    \"primary_metric\": \u0027normalized_root_mean_squared_error\u0027,\n",
                                     "    \"max_concurrent_iterations\": 5,\n",
                                     "    \"time_column_name\": time_column_name,\n",
                                     "    \"debug_log\": \u0027automl_forecast_batchai.log\u0027,\n",
                                     "}\n",
                                     "\n",
                                     "automl_config = AutoMLConfig(task = \u0027forecasting\u0027,\n",
                                     "                             path = project_folder, \n",
                                     "                             compute_target = compute_target,\n",
                                     "                             data_script = project_folder + \"/get_data.py\",\n",
                                     "                             run_configuration=conda_run_config,\n",
                                     "                             **automl_settings\n",
                                     "                            )\n"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Train the Models\n",
                                     "\n",
                                     "Call the `submit` method on the experiment object and pass the run configuration. For remote runs the execution is asynchronous, so you will see the iterations get populated as they complete. You can interact with the widgets and models even when the experiment is running to retrieve the best model up to that point. Once you are satisfied with the model, you can cancel a particular iteration or the whole run.\n",
                                     "\n",
                                     "In this example, we specify `show_output = False` to suppress console output while the run is in progress."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "remote_run = experiment.submit(automl_config, show_output = False)"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "#### Widget for Monitoring Runs\n",
                                     "\n",
                                     "The widget will first report a \"loading\" status while running the first iteration. After completing the first iteration, an auto-updating graph and table will be shown. The widget will refresh once per minute, so you should see the graph update as child runs complete.\n",
                                     "\n",
                                     "You can click on a pipeline to see run properties and output logs.  Logs are also available on the DSVM under `/tmp/azureml_run/{iterationid}/azureml-logs`\n",
                                     "\n",
                                     "**Note:** The widget displays a link at the bottom. Use this link to open a web interface to explore the individual run details."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "from azureml.widgets import RunDetails\n",
                                     "RunDetails(remote_run).show()"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# Wait until the run finishes.\n",
                                     "remote_run.wait_for_completion(show_output = True)"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "### Pre-process cache cleanup\n",
                                     "The preprocess data gets cache at user default file store. When the run is completed the cache can be cleaned by running below cell"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "remote_run.clean_preprocessor_cache()"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "### Retrieve the Best Model\n",
                                     "\n",
                                     "Below we select the best pipeline from our iterations. The `get_output` method returns the best run and the fitted model. The Model includes the pipeline and any pre-processing.  Overloads on `get_output` allow you to retrieve the best run and fitted model for *any* logged metric or for a particular *iteration*."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "best_run, fitted_model = remote_run.get_output()\n",
                                     "print(best_run)\n",
                                     "print(fitted_model)"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "df = pd.read_csv(\"https://automldata.blob.core.windows.net/datasets/nyc_energy.csv\", parse_dates=[\u0027timeStamp\u0027])\n",
                                     "test = df[df[\u0027timeStamp\u0027] \u003e= \u00272017-02-01\u0027]\n",
                                     "y_test = test.pop(\u0027demand\u0027).values\n",
                                     "X_test = test"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "y_pred = fitted_model.predict(X_test)\n",
                                     "y_pred"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "def _check_calc_input(y_true, y_pred, rm_na=True):\n",
                                     "    \"\"\"\n",
                                     "    Check that \u0027y_true\u0027 and \u0027y_pred\u0027 are non-empty and\n",
                                     "    have equal length.\n",
                                     "\n",
                                     "    :param y_true: Vector of actual values\n",
                                     "    :type y_true: array-like\n",
                                     "\n",
                                     "    :param y_pred: Vector of predicted values\n",
                                     "    :type y_pred: array-like\n",
                                     "\n",
                                     "    :param rm_na:\n",
                                     "        If rm_na=True, remove entries where y_true=NA and y_pred=NA.\n",
                                     "    :type rm_na: boolean\n",
                                     "\n",
                                     "    :return:\n",
                                     "        Tuple (y_true, y_pred). if rm_na=True,\n",
                                     "        the returned vectors may differ from their input values.\n",
                                     "    :rtype: Tuple with 2 entries\n",
                                     "    \"\"\"\n",
                                     "    if len(y_true) != len(y_pred):\n",
                                     "        raise ValueError(\n",
                                     "            \u0027the true values and prediction values do not have equal length.\u0027)\n",
                                     "    elif len(y_true) == 0:\n",
                                     "        raise ValueError(\n",
                                     "            \u0027y_true and y_pred are empty.\u0027)\n",
                                     "    # if there is any non-numeric element in the y_true or y_pred,\n",
                                     "    # the ValueError exception will be thrown.\n",
                                     "    y_true = np.array(y_true).astype(float)\n",
                                     "    y_pred = np.array(y_pred).astype(float)\n",
                                     "    if rm_na:\n",
                                     "        # remove entries both in y_true and y_pred where at least\n",
                                     "        # one element in y_true or y_pred is missing\n",
                                     "        y_true_rm_na = y_true[~(np.isnan(y_true) | np.isnan(y_pred))]\n",
                                     "        y_pred_rm_na = y_pred[~(np.isnan(y_true) | np.isnan(y_pred))]\n",
                                     "        return (y_true_rm_na, y_pred_rm_na)\n",
                                     "    else:\n",
                                     "        return y_true, y_pred"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "y_test,y_pred =  _check_calc_input(y_test,y_pred)"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "print(\"[Test Data] \\nRoot Mean squared error: %.2f\" % np.sqrt(mean_squared_error(y_test, y_pred)))\n",
                                     "# Explained variance score: 1 is perfect prediction\n",
                                     "print(\u0027mean_absolute_error score: %.2f\u0027 % mean_absolute_error(y_test, y_pred))\n",
                                     "print(\u0027R2 score: %.2f\u0027 % r2_score(y_test, y_pred))\n",
                                     "\n",
                                     "\n",
                                     "\n",
                                     "# Plot outputs\n",
                                     "%matplotlib notebook\n",
                                     "from matplotlib import pyplot as plt\n",
                                     "from matplotlib.pyplot import imshow\n",
                                     "test_pred = plt.scatter(y_test, y_pred, color=\u0027b\u0027)\n",
                                     "test_test = plt.scatter(y_test, y_test, color=\u0027g\u0027)\n",
                                     "plt.legend((test_pred, test_test), (\u0027prediction\u0027, \u0027truth\u0027), loc=\u0027upper left\u0027, fontsize=8)\n",
                                     "plt.show()"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [

                                 ]
                  }
              ],
    "metadata":  {
                     "authors":  [
                                     {
                                         "name":  "xiaga"
                                     }
                                 ],
                     "kernelspec":  {
                                        "display_name":  "Python 3.6 - AzureML",
                                        "language":  "python",
                                        "name":  "python3-azureml"
                                    },
                     "language_info":  {
                                           "codemirror_mode":  {
                                                                   "name":  "ipython",
                                                                   "version":  3
                                                               },
                                           "file_extension":  ".py",
                                           "mimetype":  "text/x-python",
                                           "name":  "python",
                                           "nbconvert_exporter":  "python",
                                           "pygments_lexer":  "ipython3",
                                           "version":  "3.6.6"
                                       }
                 },
    "nbformat":  4,
    "nbformat_minor":  2
}
