{
    "cells":  [
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "# AutoML 012: categorical-feature-transformation-test\n",
                                     "Copyright (c) Microsoft Corporation. All rights reserved.\n",
                                     "\n",
                                     "Licensed under the MIT License."
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "\n",
                                     "In this example we demonstrate how AutoML\u0027s extracts categorical features from categorical data.\n",
                                     "\n",
                                     "Make sure you have executed the [setup](setup.ipynb) before running this notebook.\n",
                                     "\n",
                                     "In this notebook you would see\n",
                                     "1. Extraction of categorical features using one hot-encoding while training\n",
                                     "2. Engineered feature names for the categorical variables\n",
                                     "3. Validation of categorical features using a validation set"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# AzureML imports\n",
                                     "import azureml.core\n",
                                     "from azureml.core import RunConfiguration\n",
                                     "from azureml.core.workspace import Workspace\n",
                                     "from azureml.core.experiment import Experiment\n",
                                     "from azureml.train.automl import AutoMLConfig\n",
                                     "from azureml.train.automl.run import AutoMLRun\n",
                                     "\n",
                                     "# Pandas and Numpy imports\n",
                                     "import logging\n",
                                     "import numpy as np\n",
                                     "import pandas as pd"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# Get the workspace\n",
                                     "ws = Workspace.from_config()\n",
                                     "\n",
                                     "# choose a name for the run history container in the workspace\n",
                                     "experiment_name = \u0027automl-local-categorical-features\u0027\n",
                                     "# project folder\n",
                                     "project_folder = \u0027./sample_projects/automl-local-categorical-features\u0027\n",
                                     "# Create an experiment\n",
                                     "experiment=Experiment(ws, experiment_name)\n",
                                     "\n",
                                     "output = {}\n",
                                     "output[\u0027SDK version\u0027] = azureml.core.VERSION\n",
                                     "output[\u0027Subscription ID\u0027] = ws.subscription_id\n",
                                     "output[\u0027Workspace Name\u0027] = ws.name\n",
                                     "output[\u0027Resource Group\u0027] = ws.resource_group\n",
                                     "output[\u0027Location\u0027] = ws.location\n",
                                     "output[\u0027Project Directory\u0027] = project_folder\n",
                                     "output[\u0027Experiment Name\u0027] = experiment.name\n",
                                     "pd.set_option(\u0027display.max_colwidth\u0027, -1)\n",
                                     "pd.DataFrame(data = output, index = [\u0027\u0027]).T"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Diagnostics\n",
                                     "Opt-in diagnostics collection for better experience, quality, and security of future releases"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "from azureml.telemetry import set_diagnostics_collection\n",
                                     "set_diagnostics_collection(send_diagnostics=True)"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Load Categorical Dataset\n",
                                     "The data set contains \"probability\" which is categorical data as it has four values of probabilities 20, 40, 60 and 80.  "
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# Columns to read from raw data\n",
                                     "fields = [\u0027label\u0027, \u0027probability\u0027]\n",
                                     "\n",
                                     "# Read the test data\n",
                                     "dataset = pd.read_csv(\u0027featurizers_test_data.csv\u0027, usecols=fields)\n",
                                     "\n",
                                     "# Number of samples in test data\n",
                                     "number_of_samples_in_test_data = 10\n",
                                     "\n",
                                     "# Output label\n",
                                     "y = dataset[\u0027label\u0027]\n",
                                     "\n",
                                     "# Training data\n",
                                     "X = dataset.drop(\u0027label\u0027, axis=1)\n",
                                     "\n",
                                     "# Dump first ten rows of X\n",
                                     "print(X.head(10))\n",
                                     "\n",
                                     "# Split the data into train and test\n",
                                     "X_train = X.iloc[0:X.shape[0] - number_of_samples_in_test_data]\n",
                                     "X_test = X.iloc[X.shape[0] - number_of_samples_in_test_data:X.shape[0]]\n",
                                     "y_train = y.iloc[0:y.shape[0] - number_of_samples_in_test_data].values\n",
                                     "y_test = y.iloc[y.shape[0] - number_of_samples_in_test_data:y.shape[0]].values"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Instantiate Auto ML Classifier\n",
                                     "\n",
                                     "Instantiate a AutoML Object This creates an Experiment in Azure ML. You can reuse this objects to trigger multiple runs. Each run will be part of the same experiment.\n",
                                     "\n",
                                     "|Property|Description|\n",
                                     "|-|-|\n",
                                     "|**primary_metric**|This is the metric that you want to optimize.\u003cbr\u003e Auto ML Classifier supports the following primary metrics \u003cbr\u003e\u003ci\u003eAUC_macro\u003c/i\u003e\u003cbr\u003e\u003ci\u003eAUC_weighted\u003c/i\u003e\u003cbr\u003e\u003ci\u003eaccuracy\u003c/i\u003e\u003cbr\u003e\u003ci\u003eweighted_accuracy\u003c/i\u003e\u003cbr\u003e\u003ci\u003enorm_macro_recall\u003c/i\u003e\u003cbr\u003e\u003ci\u003ebalanced_accuracy\u003c/i\u003e\u003cbr\u003e\u003ci\u003eaverage_precision_score_weighted\u003c/i\u003e|\n",
                                     "|**iteration_timeout_minutes**|Time limit in minutes for each iterations|\n",
                                     "|**iterations**|Number of iterations. In each iteration Auto ML Classifier trains the data with a specific pipeline|\n",
                                     "|**n_cross_validations**|Number of cross validation splits|"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Training the Model\n",
                                     "\n",
                                     "You can call the fit method on the AutoML instance and pass the run configuration. For Local runs the execution is synchronous. Depending on the data and number of iterations this can run for while.\n",
                                     "You will see the currently running iterations printing to the console.\n",
                                     "\n",
                                     "*fit* method on Auto ML Classifier triggers the training of the model. It can be called with the following parameters\n",
                                     "\n",
                                     "|**Parameter**|**Description**|\n",
                                     "|-|-|\n",
                                     "|**X**|(sparse) array-like, shape = [n_samples, n_features]|\n",
                                     "|**y**|(sparse) array-like, shape = [n_samples, ], [n_samples, n_classes]\u003cbr\u003eMulti-class targets. An indicator matrix turns on multilabel classification.  This should be an array of integers. |\n",
                                     "|**compute_target**|Indicates the compute used for training. \u003ci\u003elocal\u003c/i\u003e indicates train on the same compute which hosts the jupyter notebook. \u003cbr\u003eFor DSVM and Batch AI please refer to the relevant notebooks.|\n",
                                     "|**show_output**| True/False to turn on/off console output|"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "automl_config = AutoMLConfig(task = \u0027classification\u0027,\n",
                                     "                             debug_log = \u0027automl_errors.log\u0027,\n",
                                     "                             primary_metric = \u0027accuracy\u0027,\n",
                                     "                             iteration_timeout_minutes = 60,\n",
                                     "                             iterations = 5,\n",
                                     "                             n_cross_validations = 4,\n",
                                     "                             preprocess=True,\n",
                                     "                             verbosity = logging.INFO,\n",
                                     "                             X = X_train, \n",
                                     "                             y = y_train,\n",
                                     "                             path=project_folder)"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Training the Model\n",
                                     "\n",
                                     "You can call the submit method on the AutoML experiment instance and pass the run configuration. For Local runs the execution is synchronous. Depending on the data and number of iterations this can run for while.\n",
                                     "You will see the currently running iterations printing to the console.\n",
                                     "\n",
                                     "*submit* method on Auto ML Classifier triggers the training of the model. It can be called with the following parameters\n",
                                     "\n",
                                     "|**Parameter**|**Description**|\n",
                                     "|-|-|\n",
                                     "|**automal_config**|Indicates the Auto configuration\n",
                                     "|**show_output**| True/False to turn on/off console output|"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "local_run = experiment.submit(automl_config, show_output=True)"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Looking at the AutoML categorical transformations"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "#### Viewing the transformed feature names\n",
                                     "\n",
                                     "Since the categorical values in the data get transformed using one-hot encoding into many features, these features are named using their engineered feature names. We can view the engineered feature names using the best model by calling the method *get_output*."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# Get the parent run\n",
                                     "parent_run = AutoMLRun(experiment=experiment, run_id=local_run.run_id)\n",
                                     "\n",
                                     "# Find the best fitted model for the given run\n",
                                     "best_run, fitted_model = parent_run.get_output(metric=\u0027accuracy\u0027)\n",
                                     "\n",
                                     "# Print the engineered feature names for categorical data\n",
                                     "print(\"List of engineered feature names\")\n",
                                     "for engineered_feature_name in fitted_model.named_steps.datatransformer.get_engineered_feature_names():\n",
                                     "    print(\u0027\\t\u0027 + engineered_feature_name)\n",
                                     "\n",
                                     "# Test if the engineered feature names for the transformed data is as per expectation\n",
                                     "expected_engineered_feature_names = [\u0027probability_CharGramCountVec_20\u0027, \n",
                                     "                                     \u0027probability_CharGramCountVec_40\u0027, \n",
                                     "                                     \u0027probability_CharGramCountVec_60\u0027, \n",
                                     "                                     \u0027probability_CharGramCountVec_80\u0027]\n",
                                     "assert all([a == b for a, b in zip(expected_engineered_feature_names, fitted_model.named_steps.datatransformer.get_engineered_feature_names())])"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "#### Transforming the test data using data transfromer\n",
                                     "Given the best fitted model, transform the test data "
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "# Transform the test data using the data transformer for categorical data\n",
                                     "x_test_transform = pd.DataFrame(fitted_model.named_steps.datatransformer.transform(X_test).todense())\n",
                                     "\n",
                                     "# Dump the transformed data\n",
                                     "print(x_test_transform)\n",
                                     "\n",
                                     "# Test the transformed data against the expected transformed data frame\n",
                                     "expected_x_test_transform = [[0, 0, 0, 1],\n",
                                     "                             [0, 1, 0, 0],\n",
                                     "                             [1, 0, 0, 0],\n",
                                     "                             [1, 0, 0, 0],\n",
                                     "                             [0, 0, 0, 1],\n",
                                     "                             [0, 0, 1, 0],\n",
                                     "                             [0, 1, 0, 0],\n",
                                     "                             [0, 1, 0, 0],\n",
                                     "                             [0, 0, 0, 1],\n",
                                     "                             [0, 0, 0, 1]]\n",
                                     "assert((x_test_transform.values == pd.DataFrame(data=expected_x_test_transform).values).all())"
                                 ]
                  }
              ],
    "metadata":  {
                     "authors":  [
                                     {
                                         "name":  "savitam"
                                     }
                                 ],
                     "kernelspec":  {
                                        "display_name":  "Python 3.6 - AzureML",
                                        "language":  "python",
                                        "name":  "python3-azureml"
                                    },
                     "language_info":  {
                                           "codemirror_mode":  {
                                                                   "name":  "ipython",
                                                                   "version":  3
                                                               },
                                           "file_extension":  ".py",
                                           "mimetype":  "text/x-python",
                                           "name":  "python",
                                           "nbconvert_exporter":  "python",
                                           "pygments_lexer":  "ipython3",
                                           "version":  "3.6.5"
                                       }
                 },
    "nbformat":  4,
    "nbformat_minor":  2
}
