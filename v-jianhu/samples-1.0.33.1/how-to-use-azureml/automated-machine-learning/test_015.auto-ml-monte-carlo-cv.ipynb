{
    "cells":  [
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "# AutoML 015: Monte Carlo CV\n",
                                     "Copyright (c) Microsoft Corporation. All rights reserved.\n",
                                     "\n",
                                     "Licensed under the MIT License."
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "\n",
                                     "In this example we use the scikit learn\u0027s [20newsgroup](In this example we use the scikit learn\u0027s [digit dataset](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html) to showcase how you can use the AutoML Classifier with Monte Carlo cross validation and sparse data.\n",
                                     "\n",
                                     "Make sure you have executed the [setup](setup.ipynb) before running this notebook.\n",
                                     "\n",
                                     "In this notebook you would see\n",
                                     "1. Creating or reusing an existing Project and Workspace\n",
                                     "2. Instantiating a AutoML Classifier \n",
                                     "4. Training the Model\n",
                                     "5. Exploring the results\n",
                                     "6. Testing the fitted model\n",
                                     "\n",
                                     "In addition this notebook showcases the following features\n",
                                     "- **Monte Carlo** cross validation\n",
                                     "- **Sparse data**"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Create Project and Workspace\n",
                                     "As part of the setup you have already created a workspace. For AutoML you would need to create a \u003cb\u003eProject\u003c/b\u003e. A Project is a local folder that contains files for your Azure ML experiments. It is associated with a run history, a cloud container of run metrics and output artifacts from your experiments. You can either attach a local folder as a new project, or load a local folder as a project if it has been attached before."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "import logging\n",
                                     "import os\n",
                                     "import random\n",
                                     "\n",
                                     "from matplotlib import pyplot as plt\n",
                                     "from matplotlib.pyplot import imshow\n",
                                     "import numpy as np\n",
                                     "import pandas as pd\n",
                                     "from sklearn import datasets\n",
                                     "\n",
                                     "import azureml.core\n",
                                     "from azureml.core.experiment import Experiment\n",
                                     "from azureml.core.workspace import Workspace\n",
                                     "from azureml.train.automl import AutoMLConfig\n",
                                     "from azureml.train.automl.run import AutoMLRun"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "ws = Workspace.from_config()\n",
                                     "\n",
                                     "# choose a name for the run history container in the workspace\n",
                                     "experiment_name = \u0027automl-local-missing-data\u0027\n",
                                     "# project folder\n",
                                     "project_folder = \u0027./sample_projects/automl-local-missing-data\u0027\n",
                                     "\n",
                                     "experiment = Experiment(ws, experiment_name)\n",
                                     "\n",
                                     "output = {}\n",
                                     "output[\u0027SDK version\u0027] = azureml.core.VERSION\n",
                                     "output[\u0027Subscription ID\u0027] = ws.subscription_id\n",
                                     "output[\u0027Workspace\u0027] = ws.name\n",
                                     "output[\u0027Resource Group\u0027] = ws.resource_group\n",
                                     "output[\u0027Location\u0027] = ws.location\n",
                                     "output[\u0027Project Directory\u0027] = project_folder\n",
                                     "output[\u0027Experiment Name\u0027] = experiment_name\n",
                                     "pd.set_option(\u0027display.max_colwidth\u0027, -1)\n",
                                     "pd.DataFrame(data=output, index=[\u0027\u0027]).T"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Diagnostics\n",
                                     "Opt-in diagnostics collection for better experience, quality, and security of future releases"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "from azureml.telemetry import set_diagnostics_collection\n",
                                     "set_diagnostics_collection(send_diagnostics=True)"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "Set your primary metric:"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {
                                       "template_template_cell":  true
                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "primary_metric = \"AUC_weighted\"\n",
                                     "data_library = \"numpy\""
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Creating Sparse Data"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "from sklearn.datasets import fetch_20newsgroups\n",
                                     "from sklearn.feature_extraction.text import HashingVectorizer\n",
                                     "from sklearn.model_selection import train_test_split\n",
                                     "\n",
                                     "remove = (\u0027headers\u0027, \u0027footers\u0027, \u0027quotes\u0027)\n",
                                     "categories = [\n",
                                     "    \u0027alt.atheism\u0027,\n",
                                     "    \u0027talk.religion.misc\u0027,\n",
                                     "    \u0027comp.graphics\u0027,\n",
                                     "    \u0027sci.space\u0027,\n",
                                     "]\n",
                                     "\n",
                                     "data_train = fetch_20newsgroups(subset=\u0027train\u0027, categories=categories,\n",
                                     "                                shuffle=True, random_state=42,\n",
                                     "                                remove=remove)"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "X_train, X_test, y_train, y_test = train_test_split(data_train.data, data_train.target, test_size=0.1, random_state=42)\n",
                                     "\n",
                                     "\n",
                                     "vectorizer = HashingVectorizer(stop_words=\u0027english\u0027, alternate_sign=False, n_features=2**16)\n",
                                     "\n",
                                     "X_train = vectorizer.transform(X_train)\n",
                                     "X_test = vectorizer.transform(X_test)\n",
                                     "\n",
                                     "summary_df = pd.DataFrame(index = [\u0027No of Samples\u0027, \u0027No of Features\u0027])\n",
                                     "summary_df[\u0027Train\u0027] = [X_train.shape[0], X_train.shape[1]]\n",
                                     "summary_df[\u0027Test\u0027] = [X_test.shape[0], X_test.shape[1]]\n",
                                     "summary_df"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Instantiate Auto ML Config object.\n",
                                     "\n",
                                     "\n",
                                     "Instantiate a AutoML config Object. This will contain all the configuration values expected by an experiment.\n",
                                     "\n",
                                     "|Property|Description|\n",
                                     "|-|-|\n",
                                     "|**primary_metric**|This is the metric that you want to optimize.\u003cbr\u003e Auto ML Classifier supports the following primary metrics \u003cbr\u003e\u003ci\u003eAUC_macro\u003c/i\u003e\u003cbr\u003e\u003ci\u003eAUC_weighted\u003c/i\u003e\u003cbr\u003e\u003ci\u003eaccuracy\u003c/i\u003e\u003cbr\u003e\u003ci\u003eweighted_accuracy\u003c/i\u003e\u003cbr\u003e\u003ci\u003enorm_macro_recall\u003c/i\u003e\u003cbr\u003e\u003ci\u003ebalanced_accuracy\u003c/i\u003e|\n",
                                     "|**iteration_timeout_minutes**|Time limit in minutes for each iterations|\n",
                                     "|**iterations**|Number of iterations. In each iteration Auto ML Classifier trains the data with a specific pipeline|\n",
                                     "|**preprocess**| *True/False* \u003cbr\u003eSetting this to *True* enables Auto ML Classifier to perform preprocessing \u003cbr\u003eon the input to handle *missing data*, and perform some common *feature extraction*\u003cbr\u003e*Note: If input data is Sparse you cannot use preprocess=True*|"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "local_run = None\n",
                                     "\n",
                                     "X_data = X_train\n",
                                     "y_data = y_train\n",
                                     "\n",
                                     "if data_library == \u0027pandas\u0027:\n",
                                     "        X_data = pd.SparseDataFrame(X_data)\n",
                                     "        y_data = pd.DataFrame(y_data)\n",
                                     "        \n",
                                     "n_cross_validations = 3\n",
                                     "automl_config = AutoMLConfig(task = \u0027classification\u0027,\n",
                                     "                             debug_log = \u0027automl_errors.log\u0027,\n",
                                     "                             primary_metric = primary_metric,\n",
                                     "                             iteration_timeout_minutes = 60,\n",
                                     "                             iterations = 10,\n",
                                     "                             n_cross_validations = n_cross_validations,\n",
                                     "                             validation_size=1 / n_cross_validations,\n",
                                     "                             verbosity = logging.INFO,\n",
                                     "                             X = X_data, \n",
                                     "                             y = y_data,\n",
                                     "                             preprocess = False,                             \n",
                                     "                             path=project_folder) "
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Training the Model\n",
                                     "\n",
                                     "You can call the submit method on the Experiment instance and pass the AutoML configuration object to it.. For Local runs the execution is synchronous. Depending on the data and number of iterations this can run for while.\n",
                                     "You will see the currently running iterations printing to the console.\n",
                                     "\n",
                                     "*submit* method on Experiment triggers the training of the model. It can be called with the following parameters\n",
                                     "\n",
                                     "|**Parameter**|**Description**|\n",
                                     "|-|-|\n",
                                     "|**automl_config**|Configuration values for the experiment.\n",
                                     "|**show_output**| True/False to turn on/off console output|"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "local_run = experiment.submit(automl_config, show_output = True)"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "## Exploring the results"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "#### Widget for monitoring runs\n",
                                     "\n",
                                     "The widget will sit on \"loading\" until the first iteration completed, then you will see an auto-updating graph and table show up. It refreshed once per minute, so you should see the graph update as child runs complete.\n",
                                     "\n",
                                     "NOTE: The widget displays a link at the bottom. This links to a web-ui to explore the individual run details."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "from azureml.widgets import RunDetails\n",
                                     "RunDetails(local_run).show() "
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "\n",
                                     "#### Retrieve All Child Runs\n",
                                     "You can also use sdk methods to fetch all the child runs and see individual metrics that we log. "
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "children = list(local_run.get_children())\n",
                                     "metricslist = {}\n",
                                     "for run in children:\n",
                                     "    properties = run.get_properties()\n",
                                     "    metrics = run.get_metrics()    \n",
                                     "    metricslist[properties[\u0027iteration\u0027]] = metrics\n",
                                     "\n",
                                     "rundata = pd.DataFrame(metricslist).sort_index(1)\n",
                                     "rundata"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "### Retrieve the Best Model\n",
                                     "\n",
                                     "Below we select the best pipeline from our iterations. The *get_output* method on automl_classifier returns the best run and the fitted model for the last *fit* invocation. There are overloads on *get_output* that allow you to retrieve the best run and fitted model for *any* logged metric or a particular *iteration*."
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "def ValidateBestFitPrimaryMetric(primary_metric, data_library):\n",
                                     "    best_run, fitted_model = local_run.get_output()\n",
                                     "    metric_value = best_run.get_metrics()[primary_metric]\n",
                                     "    if not (.90 \u003c float(metric_value) \u003c= 1):\n",
                                     "        raise Exception(\u0027Metric value of {0} is not in the valid range.\u0027.format(metric_value))\n",
                                     "        \n",
                                     "ValidateBestFitPrimaryMetric(primary_metric, data_library)"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "#### Best Model based on any other metric"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "def ValidateBestFitOtherMetric(primary_metric, data_library):\n",
                                     "    best_run, fitted_model = local_run.get_output(metric=primary_metric)\n",
                                     "    if fitted_model == None:\n",
                                     "        raise Exception(\u0027Fitted model is None for {metric}.\u0027.format(metric=primary_metric))\n",
                                     "        \n",
                                     "ValidateBestFitOtherMetric(primary_metric, data_library)"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "#### Best Model based on any iteration"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "def ValidateAllModelsPrimaryMetric(primary_metric, data_library):\n",
                                     "    for iteration in range(0, 10):\n",
                                     "        best_run, fitted_model = local_run.get_output(iteration=iteration)        \n",
                                     "        try:\n",
                                     "            fitted_model.predict(X_data[[0]])\n",
                                     "        except Exception as e:\n",
                                     "            raise Exception(\u0027Invalid fitted model returned for iteration\u0027\n",
                                     "                            \u0027 {0} for AUC_macro.\u0027.format(iteration)) from e\n",
                                     "    print(\"\\n Finished running \u0027ValidateAllModelsPrimaryMetric\u0027\")     \n",
                                     "ValidateAllModelsPrimaryMetric(primary_metric, data_library)"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "### Register fitted model for deployment"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "description = \u0027AutoML Model\u0027\n",
                                     "tags = None\n",
                                     "local_run.register_model(description=description, tags=tags)\n",
                                     "local_run.model_id # Use this id to deploy the model as a web service in Azure"
                                 ]
                  },
                  {
                      "cell_type":  "markdown",
                      "metadata":  {

                                   },
                      "source":  [
                                     "### Testing the Fitted Model "
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [
                                     "digits = datasets.load_digits()### Testing the Fitted Model\n",
                                     "\n",
                                     "#### Load Test Data\n",
                                     "import sklearn\n",
                                     "from pandas_ml import ConfusionMatrix\n",
                                     "\n",
                                     "\n",
                                     "remove = (\u0027headers\u0027, \u0027footers\u0027, \u0027quotes\u0027)\n",
                                     "categories = [\n",
                                     "    \u0027alt.atheism\u0027,\n",
                                     "    \u0027talk.religion.misc\u0027,\n",
                                     "    \u0027comp.graphics\u0027,\n",
                                     "    \u0027sci.space\u0027,\n",
                                     "]\n",
                                     "\n",
                                     "\n",
                                     "data_test = fetch_20newsgroups(subset=\u0027test\u0027, categories=categories,\n",
                                     "                                shuffle=True, random_state=42,\n",
                                     "                                remove=remove)\n",
                                     "\n",
                                     "vectorizer = HashingVectorizer(stop_words=\u0027english\u0027, alternate_sign=False,\n",
                                     "                               n_features=2**16)\n",
                                     "\n",
                                     "X_test = vectorizer.transform(data_test.data)\n",
                                     "y_test = data_test.target\n",
                                     "\n",
                                     "#### Testing our best pipeline\n",
                                     "\n",
                                     "def TestPipeline(primary_metric, data_library):\n",
                                     "    best_run, fitted_model = local_run.get_output()\n",
                                     "    ypred = fitted_model.predict(X_test)\n",
                                     "    ypred_strings = [categories[i] for i in ypred]\n",
                                     "    ytest_strings = [categories[i] for i in y_test]\n",
                                     "\n",
                                     "    cm = ConfusionMatrix(ytest_strings, ypred_strings)\n",
                                     "    print(cm)\n",
                                     "    cm.plot()\n",
                                     "TestPipeline(primary_metric, data_library)"
                                 ]
                  },
                  {
                      "cell_type":  "code",
                      "execution_count":  null,
                      "metadata":  {

                                   },
                      "outputs":  [

                                  ],
                      "source":  [

                                 ]
                  }
              ],
    "metadata":  {
                     "authors":  [
                                     {
                                         "name":  "savitam"
                                     }
                                 ],
                     "kernelspec":  {
                                        "display_name":  "Python 3.6 - AzureML",
                                        "language":  "python",
                                        "name":  "python3-azureml"
                                    },
                     "language_info":  {
                                           "codemirror_mode":  {
                                                                   "name":  "ipython",
                                                                   "version":  3
                                                               },
                                           "file_extension":  ".py",
                                           "mimetype":  "text/x-python",
                                           "name":  "python",
                                           "nbconvert_exporter":  "python",
                                           "pygments_lexer":  "ipython3",
                                           "version":  "3.6.5"
                                       }
                 },
    "nbformat":  4,
    "nbformat_minor":  2
}
